# -*- coding: utf-8 -*-
"""BAB 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F9mgeyB7mNbfafpsVN1Tc6cCzJ2SZO2U

Bab 2: Supervised Learning (Pembelajaran Terawasi)

1. Tujuan
Bab ini membahas secara mendalam pembelajaran terawasi, termasuk algoritma seperti k-Nearest Neighbors, model linear, pohon keputusan, dan lainnya. Selain itu, dijelaskan juga konsep penting seperti overfitting dan underfitting.

2. Implementasi Kode
"""

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

# Load dataset Iris
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris['data'], iris['target'], random_state=0
)

# Membuat model k-NN dengan k=3
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)

# Evaluasi model
accuracy = knn.score(X_test, y_test)
print("Akurasi k-NN:", accuracy)

"""2.2 Logistic Regression (Regresi Logistik)"""

from sklearn.linear_model import LogisticRegression

# Membuat model regresi logistik
logreg = LogisticRegression(max_iter=200)
logreg.fit(X_train, y_train)

# Evaluasi model
accuracy = logreg.score(X_test, y_test)
print("Akurasi Logistic Regression:", accuracy)

"""2.3 Decision Tree (Pohon Keputusan)"""

from sklearn.tree import DecisionTreeClassifier

# Membuat model pohon keputusan
tree = DecisionTreeClassifier(max_depth=3, random_state=0)
tree.fit(X_train, y_train)

# Evaluasi model
accuracy = tree.score(X_test, y_test)
print("Akurasi Decision Tree:", accuracy)

""" 2.4 Support Vector Machine (SVM)"""

from sklearn.svm import SVC

# Membuat model SVM dengan kernel linear
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)

# Evaluasi model
accuracy = svm.score(X_test, y_test)
print("Akurasi SVM:", accuracy)

"""3.1 Konsep Dasar Supervised Learning
Supervised learning adalah metode pembelajaran di mana model dilatih menggunakan data dengan label yang sudah diketahui. Tujuan utamanya adalah memprediksi label untuk data baru yang tidak diketahui.

3.2 Overfitting dan Underfitting
- Overfitting: Model terlalu kompleks sehingga "menghapal" data training dan tidak mampu generalisasi pada data baru.
- Underfitting: Model terlalu sederhana sehingga tidak bisa menangkap pola dalam data.

3.3 Model-Model yang Dibahas
- k-NN: Algoritma yang memprediksi berdasarkan tetangga terdekat dalam ruang fitur.
- Logistic Regression: Model linear untuk klasifikasi yang memanfaatkan fungsi logistik.
- Decision Tree: Model berbasis pohon yang membagi data menjadi cabang berdasarkan fitur tertentu.
- SVM: Algoritma yang mencari hyperplane terbaik untuk memisahkan kelas dalam ruang fitur.

4. Insight & Ringkasan
- Berbagai algoritma supervised learning memiliki kelebihan dan kekurangan masing-masing:
  - k-NN cocok untuk dataset kecil dan sederhana.
  - Logistic Regression efektif untuk dataset linear.
  - Decision Tree fleksibel tapi rentan overfitting.
  - SVM kuat dalam memisahkan data kompleks.
- Pemilihan algoritma bergantung pada sifat data dan kebutuhan aplikasi.

"""